{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Machine Learning Notes - 1.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM3v1Yveu7BAEzDcDg61tyD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harishbhagtani/machine-learning-notes/blob/main/Machine_Learning_Notes_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RABhCN800ZI0"
      },
      "source": [
        "# Machine Learning Basics\n",
        "\n",
        "\n",
        "\n",
        "*   Machine learning is a science of programming computers so that they can learn from data\n",
        "*   Phrase **\"Machine Learning\"** came into existence in 1952.\n",
        "*   **\"A Computer program is said to learn from experience E with respect to some task T and some performance measure P, if it's performance P, improves with experience E.\"**\n",
        "\n",
        "*   Example : Spam Filter, Voice Recognition System, Text to Speech System\n",
        "\n",
        "# Importance of Machine Learning\n",
        "\n",
        "*   Complex problems for which there is no good solution at all using a traditional approach: the best Machine Learning techniques can find a solution.\n",
        "\n",
        "*   Fluctuating environments: a Machine Learning system can adapt to new data.\n",
        "\n",
        "# Types of Machine learning Algorithms\n",
        "\n",
        "* Supervised Learning - Requires Human Supervision.\n",
        "\n",
        "* Unsupervised Learning - Do not require human supervision.\n",
        "\n",
        "* Semi-Supervised learning - Requires partial human supervision\n",
        "\n",
        "* Online learning algorithm - Learn inrementally on the internet.\n",
        "\n",
        "* Batch learning algorithm - Do not learn incrementally on the internet. Can be trained only once and need to be taken off the system and  retrained again.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "# Supervised Learning\n",
        "\n",
        "* Training data that is feeded to the algorithm includes desired soltion : Labels.\n",
        "\n",
        "* Main task here is classification and to predict a target numerical value from a given set of features that are called predictor.\n",
        "\n",
        "* Example Algorithms: \n",
        "    * k-Nearest Neighbours\n",
        "    * Linear Regression\n",
        "    * Logistic Regression\n",
        "    * Decision Trees and Random Forest\n",
        "    * Neural Networks\n",
        "\n",
        "# Unsupervised Learning\n",
        "\n",
        "* In Unsupervised Learning, the training data is unlabelled. The system tried to learn without a teacher (labelled features).\n",
        "\n",
        "* Example Algorithms: \n",
        "    * Clustring - Recongnizing the clusters of similar data\n",
        "      * K-Means\n",
        "      * DBSCAN\n",
        "      * Hierarchical Cluster Analysis\n",
        "    * Anomaly Detection - Detection of unusual data in a dataset \n",
        "      * One class SVM\n",
        "      * Isolation Forest\n",
        "    * Visualization and Dimentionality Reduction - Simlifying data without losing too much information\n",
        "      * Principal Component Analysis (PCA)\n",
        "      * Kernel PCA\n",
        "      * Locally Linear Embedding(LLE)\n",
        "      * t-distributed Scholastic Neighbor Embedding (t-SNE)\n",
        "    * Association Rule Learning - Dig into large amount of data and discover interesting relation between attributes\n",
        "      * Apriori\n",
        "      * Eclat\n",
        "\n",
        "\n",
        "# Semi Supervised Learning\n",
        "\n",
        "* Partially labelled and a lot of un-labelled data.\n",
        "\n",
        "* Most algorithms are combination of **Supervised** and **Unsupervised Learning**\n",
        "\n",
        "* Example Techniques\n",
        "    * Deep Belief Networks (DBNs)\n",
        "    * Restricted Boltzman Machines (RBMs)\n",
        "\n",
        "# Reinforcement Learning\n",
        "\n",
        "* Here, the learning system, called an **Agent** can observe environment, select and perform actions and get the **rewards** in return.\n",
        "\n",
        "* It learns by itself the best strategy to perform some action, which is called policy, to get the most award over time.\n",
        "\n",
        "* A policy defines what action the agent should choose when it is in a given situation.\n",
        "\n",
        "* Example: DeepMind's Alpha GO (2017) program is a good example of Reinforcement learning.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "# Batch Learning\n",
        "\n",
        "* In batch learning, the system is incapable of learning incrementally: It must be trained using all teh available data. \n",
        "\n",
        "* It takes a lot of time and computing resources, so it is typically done offline. \n",
        "\n",
        "* In this, first a system is trained, then launched into production and runs without learning anymore. \n",
        "\n",
        "* If we want to update the batch learning system, we'll need to train the whole system from scratch on the full dataset, then stop the system and replace it with new one. \n",
        "\n",
        "# Online Learning\n",
        "\n",
        "* In online learning, you train the system incrementally by feeding it data and instances sequentially, either individually or in small groups known as mini-batches.\n",
        "\n",
        "* Each learning step is fast and cheap.\n",
        "\n",
        "* Needs limited computing resources and can adapt to change rapidly.\n",
        "\n",
        "* **Learning Rate** - It is one important parameter of online leraning system that tells how fast a system adapts to changing data. **High** learning rate means system adapts to change quickly. **Low** learning rate means system adapts to change slowly.\n",
        "\n",
        "* If **bad data** is fed to the system, the system's performance will gradually decline. If we're talking about live system's, your client will notice.\n",
        "\n",
        "* Constant monitoring of the system is required to reduce the risks and maintaing high quality data.\n",
        "\n",
        "# Instance Based Learning\n",
        " \n",
        "* In instance based learning, the system learns the examples by heart, then generalize to new cases by comparing them with learned examples.\n",
        "\n",
        "* If we create a spam filter this way, it'll mark all email spam that are identical to the emails that've already marked by the user.\n",
        "\n",
        "# Model Based Learning\n",
        "\n",
        "* Another way to generalize is from the set of examples to build a model of these examples and use that model to make predictions. This is known as model based learning.\n",
        "\n",
        "* Steps for model based Learning - \n",
        "  * **Study the data**.\n",
        "  * **Select a model.**\n",
        "  * **Train the model** on training data (i.e. the learning algorithm searched for the model parameter values that minimizes a cost function).\n",
        "  * Finally, **apply the model** to make new predictions on new cases, hoping that model will generalize well.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9hOWW9o270cE"
      },
      "source": [
        "# Main Challanges of Machine Learning\n",
        "\n",
        "* Main task in machine learning is to **Select a Learning Algorithm** and tain it on some **Data**.\n",
        "\n",
        "* There are two things that can go wrong: \"**Bad Algorithm**\" and \"**Bad Data**\".\n",
        "\n",
        "### **Examples of Bad Data**\n",
        "\n",
        "1. **In-sufficiant Quantity of Training Data** - It takes a lot of data for most machine learning algorithms to work properly. Even for a small problem, you typically need thousands of examples, and for complex problems such as image or speech recognition, you may need millions of examples. (Unless you reuse parts of existing model)\n",
        "\n",
        "#### Unreasonable effectiveness of Data\n",
        "\n",
        "* Paper published in 2001\n",
        "\n",
        "*  Very different Machine Learning algorithms, including fairly simple ones, performed almost identically well on a complex problem of natural language disambiguation once they were given enough data.\n",
        "\n",
        "As the authors put it: **“these results suggest that we may want to reconsider the trade- off between spending time and money on algorithm development versus spending it on corpus development.”**\n",
        "\n",
        "**Note** - It is not always easy or cheap to get extra training data, so in most such cases, choosing a proper algorithm is important.\n",
        "\n",
        "2. **Non-Representative Training Data** - Training data must be representative of all the new cases you want to generalize to. This is true for both instance and model based learning. In short, **\"Adding new data shouldn't significantly change the model and the model should generalize well to the new data\"**\n",
        "\n",
        "* If the data sample is too small, you'll have **sampling noise** (i.e. non-representative data), but even very large data samples can be non-representative if the sampling method is flawed.\n",
        "\n",
        "3. **Poor Quality Data**\n",
        "\n",
        "* If the trainig data is full of errors, outliers, and noise (e.g. due to poor quality measurements), it will make it harder for system to detect underlying patterns, so the system is less likely to perform.\n",
        "\n",
        "* The significant part of building a machine learning model is to **clean up the training data**. For example:\n",
        "\n",
        "    * If some instances are clearly **outliers**, discard them or fix the error manually.\n",
        "\n",
        "    * If some instances are missing some features (e.g. 5% of customers didn't specify their age), you must decide if you want to ignore that feature altogether, ignore these instances, fill the missing values or train one model with the feature and one without it and test which works the best.\n",
        "\n",
        "4. **Irrelevant Features** -  Your system will only be capable of learning if the training data contains enough relevant features and not too many irrelevant ones.\n",
        "\n",
        "* The most important part of building a model is selection of most relevant and good features to train on. This process is known as **feature engineering** and it involes the following steps: \n",
        "\n",
        "    * **Feature Selection** - Selecting the most useful features to train among existing features.\n",
        "    * **Feature Extraction** -  Combining existing features to produce a more useful one.\n",
        "    * Creating new features by gathering new data.\n",
        "\n",
        "5. **Overfitting the training data** - It means that the model performs well on training data, but doesn't generalize the output well.\n",
        "\n",
        "* Complex models, such as deep neural networks can detect subtle patters in data, but if training set is too noisy or small (which introduces sampling bias) then model is likely to detect **pattern in noise** itself.\n",
        "\n",
        "* Overfitting happens when the model is too complex relative to the amount and noisiness of the training data. **The possible solutions are**:\n",
        "    * **To simplify the model by selecting one with fewer parameters** (e.g., a linear model rather than a high-degree polynomial model), by reducing the number of attributes in the training data or by constraining the model.\n",
        "    * To gather **more training data**\n",
        "    * To **reduce the noise** in the training data (e.g., fix data errors and remove outliers)\n",
        "\n",
        "* **Regularisation** - Constraining a model to make it simpler and reduce the risk of overfitting is called regularization. \n",
        "\n",
        "\n",
        "6. **Underfitting the training data** \n",
        "\n",
        "* **Opposite** of Overfitting.\n",
        "* Model is too simple to learn the underlying structure of data.\n",
        "* **The main options to fix this problem are:**\n",
        "  * Selecting a **more powerful model**, with more parameters\n",
        "  * **Feeding better features** to the learning algorithm (feature engineering)\n",
        "  * **Reducing the constraints** on the model (e.g., reducing the regularization hyper‐ parameter)\n",
        "\n",
        "  ---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UWUFAOt2KLea"
      },
      "source": [
        ""
      ]
    }
  ]
}